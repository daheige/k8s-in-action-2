公司内网安装

设置好yum，k8s，docker的repo，从制品库获取




setenforce 0
systemctl disable firewalld && systemctl stop firewalld
sysctl -w net.bridge.bridge-nf-call-iptables=1
echo "net.bridge.bridge-nf-call-iptables=1" > /etc/sysctl.d/k8s.conf
swapoff -a && sed -i '/ swap / s/^/#/' /etc/fstab

使用docker的rpm包安装docker-ce-18.09.9
rpm -Uvh --force --nodeps *.rpm


yum install -y kubelet-1.14.1
会安装依赖kubernetes-cni-0.7.5-0
yum install -y kubectl-1.14.1 kubeadm-1.14.1


systemctl enable docker && systemctl start docker
systemctl enable kubelet && systemctl start kubelet
hostnamectl --static set-hostname node2.k8s

192.168.41.213 master.k8s
192.168.41.89 node1.k8s
192.168.41.212 node2.k8s


vim /etc/docker/daemon.json
{"insecure-registries": ["art.sinovatio.com"]}
systemctl daemon-reload
systemctl restart docker


## 可以这样下载，然后
## docker tag art.sinovatio.com/public-docker/kubeimage/kube-apiserver:v1.14.1          k8s.gcr.io/kube-apiserver:v1.14.1
## docker tag art.sinovatio.com/public-docker/kubeimage/kube-controller-manager:v1.14.1 k8s.gcr.io/kube-controller-manager:v1.14.1
## docker tag art.sinovatio.com/public-docker/kubeimage/kube-scheduler:v1.14.1          k8s.gcr.io/kube-scheduler:v1.14.1
## docker tag art.sinovatio.com/public-docker/kubeimage/kube-proxy:v1.14.1              k8s.gcr.io/kube-proxy:v1.14.1
## docker tag art.sinovatio.com/public-docker/kubeimage/pause:3.1                       k8s.gcr.io/pause:3.1
## docker tag art.sinovatio.com/public-docker/kubeimage/etcd:3.3.10                     k8s.gcr.io/etcd:3.3.10
## docker tag art.sinovatio.com/public-docker/coredns/coredns:1.3.1                     k8s.gcr.io/coredns:1.3.1
## 或者直接docker load < k8s-114-images.tar.gz


docker pull art.sinovatio.com/public-docker/kubeimage/kube-apiserver:v1.14.1
docker pull art.sinovatio.com/public-docker/kubeimage/kube-controller-manager:v1.14.1
docker pull art.sinovatio.com/public-docker/kubeimage/kube-scheduler:v1.14.1
docker pull art.sinovatio.com/public-docker/kubeimage/kube-proxy:v1.14.1
docker pull art.sinovatio.com/public-docker/kubeimage/pause:3.1
docker pull art.sinovatio.com/public-docker/kubeimage/etcd:3.3.10
docker pull art.sinovatio.com/public-docker/coredns/coredns:1.3.1


kubeadm init配置主节点
## 要与flannel.yaml中的ConfigMap里的net-conf.json的Network对应
kubeadm init --pod-network-cidr 10.244.0.0/16

## 最后有一串token
Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.41.213:6443 --token qv79ql.q127uasxwgz1vvc3 \
    --discovery-token-ca-cert-hash sha256:7277a565ee702f75e4b709be2ec9f3701ec9ff1ee2bea24eb41a4b6b1430de27

export KUBECONFIG=/etc/kubernetes/admin.conf

kubectl get no


kubeadm init配置2个工作节点
kubeadm join 192.168.41.213:6443 --token b5ssfm.ym3ny2sxa902yro2 --discovery-token-ca-cert-hash sha256:30e6888cc39e071137d271a4fc723ffb834762db44bd6d23c4b8e20c7f64e16c


配置容器网络



回滚
rm -fr /etc/kubernetes
rm -fr /var/lib/etcd
每个节点都执行
kubeadm reset